# HumaniPro

## SetUp

```
conda create -n humanipro python==3.8
conda activate humanipro
```

Download the Isaac Gym Preview 4 release from the [website](https://developer.nvidia.com/isaac-gym), then
follow the installation instructions in the documentation. We highly recommend using a conda environment
to simplify set up.

Ensure that Isaac Gym works on your system by running one of the examples from the `python/examples`
directory, like `joint_monkey.py`. Follow troubleshooting steps described in the Isaac Gym Preview 4
install instructions if you have any trouble running the samples.

```
pip install -r requirements.txt
```

FPS: 1/180s for all task.

## Human Model

### Human model data preparation

It only needs to consider this section when adding new motions. Otherwise, the warning about the lack of FBX does not have any real impact.

You can get all [CMU Mocap dataset](http://mocap.cs.cmu.edu/resources.php) in FBX format from [here](https://data.4tu.nl/datasets/0448aab2-3332-449f-a8e2-d208cb58c7df). Different T-Pose comes from [here](https://github.com/anishhdiwan/near/tree/main/isaacgymenvs/tasks/amp/poselib/data).

First, install FBX Python SDK.

```
conda create -n newhm python==3.10
conda activate newhm
wget https://damassets.autodesk.net/content/dam/autodesk/www/files/fbx202037_fbxpythonsdk_linux.tar.gz
tar -xzvf fbx202037_fbxpythonsdk_linux.tar.gz 
chmod ugo+x fbx202037_fbxpythonsdk_linux
sudo mkdir /usr/fbx202037_fbxpythonsdk_linux
sudo ./fbx202037_fbxpythonsdk_linux /usr/fbx202037_fbxpythonsdk_linux
cd /usr/fbx202037_fbxpythonsdk_linux
pip install fbx-2020.3.7-cp310-cp310-manylinux1_x86_64.whl
cd ~/source/HumaniPro
pip install -r reqirements_hm.txt 
```

Second, download your data and put it into `isaacgymenvs/tasks/amp/poselib/data`.
Change filename in `isaacgymenvs/tasks/amp/poselib/fbx_importer.py`

Then

```
cd isaacgymenvs/tasks/amp/poselib/
PYTHONPATH=/home/haofei/source/HumaniPro/ python fbx_importer.py
PYTHONPATH=/home/haofei/source/HumaniPro/ python retarget_motion.py 
cd ../../../../
```

We attempt to add 14.06

### Train

For task `walk`, `run`, `dance`, we use `train=HumanoidAMPPO`

```
python train.py task=HumanoidAMP
```

Register for [wandb](https://wandb.ai) and create a project named isaacgymenvs in wandb. Then, you can visualize the training process in the cloud using the following parameters.

```
wandb login
python train.py task=HumanoidAMP wandb_activate=True
```

### Test

```
python train.py task=HumanoidAMP checkpoint=checkpoints/walk_amp.pth test=True num_envs=1
```

## HumaniPro

### Human Motion Poior

Discriminator $D(s,a)$ is trained to predict whether a given state $s$ and action $a$ is sampled from the demonstrations $M$ or generated by running the policy $\pi$.

With Human Motion Poior, reward function is $r = - log(1 - \frac{1}{1+e^{-D(s_t, a_t)}})$.

Without Human Motion Poior, reward function is $r = 1$.

### Single-Agent RL (SARL, PPO)

$\hat{A}(s.a) = \hat{A}^p_{\text{GAE}}(s, a^p).$

```
python train.py task=HumanoidAMP train=HumanoidAMPPro mode=sarl wandb_activate=True
python train.py task=HumanoidAMP train=HumanoidAMPPro mode=sarl wandb_activate=True mhp=false
python train.py task=HumanoidAMP test=True num_envs=1 train=HumanoidAMPPro mode=sarl checkpoint=**.pth
```

<!--Results:
- Bad result (Walk, lr = $8.0 \times 10^{-8}$)
```
python train.py task=HumanoidAMP test=True num_envs=1 train=HumanoidAMPPro mode=sarl checkpoint=runs/HumanoidAMP_29-22-25-42/nn/HumanoidAMP_29-22-25-55_5000.pth
```
- Good result (Walk, lr = $5.0 \times 10^{-5}$)
```
python train.py task=HumanoidAMP test=True num_envs=1 train=HumanoidAMPPro mode=sarl checkpoint=runs/HumanoidAMP_21-17-21-51/nn/HumanoidAMP_21-17-22-02_150.pth
```-->

### Multi-Agent RL (MARL, ours)

$\hat{A}(s.a) = \hat{A}_{\text{GAE}}(s, a)$.

```
python train.py task=HumanoidAMP train=HumanoidAMPPro mode=marl wandb_activate=True
python train.py task=HumanoidAMP train=HumanoidAMPPro mode=marl wandb_activate=True mhp=false
python train.py task=HumanoidAMP test=True num_envs=1 train=HumanoidAMPPro mode=marl checkpoint=**.pth
```

### Multi-Agent RL with Oracle (MARL-oracle, ours-oracle)

$\hat{A}(s.a) = A(s, a)$.

```
python train.py task=HumanoidAMP train=HumanoidAMPPro mode=oracle wandb_activate=True
python train.py task=HumanoidAMP train=HumanoidAMPPro mode=oracle wandb_activate=True mhp=false
python train.py task=HumanoidAMP test=True num_envs=1 train=HumanoidAMPPro mode=oracle checkpoint=**.pth
```

<!--Results:
- Good result (Walk, lr = $5.0 \times 10^{-5}$)
```
python train.py task=HumanoidAMP test=True num_envs=1 train=HumanoidAMPPro mode=marl checkpoint=runs/HumanoidAMP_21-17-22-07/nn/HumanoidAMP_21-17-22-17_150.pth
```-->

## Result

### Storage


|                    | walk                    | run                     | dance                   | gym | some action |
| ------------------ | ----------------------- | ----------------------- | ----------------------- | --- | ----------- |
| AMP                | HumanoidAMP_28-23-29-05 | HumanoidAMP_21-23-21-08 | HumanoidAMP_21-23-22-12 |     |             |
| PPO                |                         |                         |                         |     |             |
| PPO w. hmp         |                         |                         |                         |     |             |
| ours               |                         |                         |                         |     |             |
| ours w. hmp        |                         |                         |                         |     |             |
| ours-oracle        |                         |                         |                         |     |             |
| ours-oracle w. hmp |                         |                         |                         |     |             |
| train file         | PPO                     | PPO                     | PPO                     | PPO |             |

### Episode Length


|                    | walk  | run   | dance | gym | some action |
| ------------------ | ----- | ----- | ----- | --- | ----------- |
| AMP                | 0.992 | 0.988 | 0.955 |     |             |
| PPO                |       |       |       |     |             |
| PPO w. hmp         |       |       |       |     |             |
| ours               |       |       |       |     |             |
| ours w. hmp        |       |       |       |     |             |
| ours-oracle        |       |       |       |     |             |
| ours-oracle w. hmp |       |       |       |     |             |
| train file         |       |       |       |     |             |

### Average discrimination logits for agent


|                    | walk   | run    | dance  | gym | some action |
| ------------------ | ------ | ------ | ------ | --- | ----------- |
| AMP                | -1.385 | -1.610 | -0.676 |     |             |
| PPO                |        |        |        |     |             |
| PPO w. hmp         |        |        |        |     |             |
| ours               |        |        |        |     |             |
| ours w. hmp        |        |        |        |     |             |
| ours-oracle        |        |        |        |     |             |
| ours-oracle w. hmp |        |        |        |     |             |
| train file         |        |        |        |     |             |
